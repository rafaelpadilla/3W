{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be897dda",
   "metadata": {},
   "source": [
    "# 📚 Unsupervised Learning and Novelty Detection (5 minutes)\n",
    "\n",
    "### What is Unsupervised Learning?\n",
    "\n",
    "**Unsupervised Learning** is a machine learning approach where we analyze data without labeled examples, seeking to discover hidden patterns, structures, or anomalies in the data.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "1. **Unlabeled Data**: Input data without target labels\n",
    "2. **Pattern Discovery**: Finding hidden structures in data\n",
    "3. **Anomaly Detection**: Identifying unusual or outlier patterns\n",
    "4. **Dimensionality Reduction**: Learning compact representations\n",
    "5. **Reconstruction**: Learning to recreate input data\n",
    "\n",
    "### Our Novelty Detection Problem: 3W Oil Well Anomaly Detection\n",
    "\n",
    "- **Objective**: Detect abnormal oil well operational states using only normal operation data\n",
    "- **Training Data**: Only class 0 (normal operation) sensor measurements\n",
    "- **Detection Target**: Identify when sensor patterns deviate from normal behavior\n",
    "- **Challenge**: Learn normal patterns to detect any deviation as potential fault\n",
    "\n",
    "### Why Novelty Detection Matters in Oil Wells:\n",
    "- **Early Warning System**: Detect problems before they escalate\n",
    "- **Unsupervised Monitoring**: No need for labeled fault examples\n",
    "- **Operational Safety**: Continuous monitoring of normal vs abnormal states\n",
    "- **Preventive Maintenance**: Identify subtle deviations before major failures\n",
    "\n",
    "### Autoencoder-Based Novelty Detection Approach:\n",
    "- **Training Phase**: Learn to reconstruct only normal operation patterns (class 0)\n",
    "- **Detection Phase**: High reconstruction error indicates potential anomaly\n",
    "- **Threshold**: Statistical approach (mean + 3×std) for anomaly scoring\n",
    "- **Evaluation**: Test how well it distinguishes normal vs fault classes\n",
    "\n",
    "### Problem Characteristics:\n",
    "- **Normal-Only Training**: Learn patterns from class 0 data exclusively\n",
    "- **Time Series**: Sequential sensor measurements requiring LSTM architecture\n",
    "- **High Dimensional**: Many sensors × time steps = complex patterns\n",
    "- **Reconstruction-Based**: Anomalies have higher reconstruction errors\n",
    "- **Threshold-Based**: Statistical approach for anomaly detection\n",
    "\n",
    "Let's explore LSTM autoencoders for oil well novelty detection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce29f117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Optimized Loading: 3W Dataset for Autoencoder Novelty Detection\n",
      "======================================================================\n",
      "📦 Importing modules... ✅\n",
      "⚙️ Optimization Settings:\n",
      "   • Single fold loading: True\n",
      "   • Target fold: fold_1\n",
      "   • Sampling enabled: True\n",
      "   • Max normal samples: 2000\n",
      "   • Max anomaly samples: 1000\n",
      "\n",
      "📂 Initializing data persistence... ✅\n",
      "⚡ Using format: pickle for maximum speed\n",
      "📁 Checking windowed directory: processed_data\\cv_splits\\windowed... ✅\n",
      "🔍 Looking for fold directories... ✅ Found 3 folds: ['fold_1', 'fold_2', 'fold_3']\n",
      "🎯 Using single fold: fold_1 for fast loading\n",
      "\n",
      "📁 Processing fold_1 (1/1)...\n",
      "   📄 Loading train data... ✅\n",
      "⚙️ Optimization Settings:\n",
      "   • Single fold loading: True\n",
      "   • Target fold: fold_1\n",
      "   • Sampling enabled: True\n",
      "   • Max normal samples: 2000\n",
      "   • Max anomaly samples: 1000\n",
      "\n",
      "📂 Initializing data persistence... ✅\n",
      "⚡ Using format: pickle for maximum speed\n",
      "📁 Checking windowed directory: processed_data\\cv_splits\\windowed... ✅\n",
      "🔍 Looking for fold directories... ✅ Found 3 folds: ['fold_1', 'fold_2', 'fold_3']\n",
      "🎯 Using single fold: fold_1 for fast loading\n",
      "\n",
      "📁 Processing fold_1 (1/1)...\n",
      "   📄 Loading train data... ✅ (176367 windows)\n",
      "      📊 Current totals: 2000 normal, 1000 anomaly\n",
      "      🎯 Sampling limits reached - stopping early\n",
      "   🎯 Sampling complete - sufficient data collected\n",
      "\n",
      "✅ Successfully loaded and separated windowed data!\n",
      "💚 Normal operation windows (class 0): 2000\n",
      "🔴 Anomaly windows (classes 1-9): 1000\n",
      "⚡ Loading time: 12.157 seconds\n",
      "📁 Files processed: 1\n",
      "\n",
      "📋 Processing sample windows... ✅\n",
      "\n",
      "🪟 Sample Normal Window (Window #1):\n",
      "   • Shape: (300, 3)\n",
      "   • Class: 0 (Normal Operation)\n",
      "   • Features: ['P-TPT_scaled', 'T-TPT_scaled', 'class']\n",
      "\n",
      "📊 Normal Operation Data (Class 0):\n",
      "   • Total windows: 2000\n",
      "   • Will be used for: Autoencoder training\n",
      "\n",
      "📊 Anomaly Data (Classes 1-9):\n",
      "   • Class 1: 513 windows\n",
      "   • Class 2: 371 windows\n",
      "   • Class 3: 116 windows\n",
      "   • Total anomaly windows: 1000\n",
      "   • Will be used for: Anomaly detection testing\n",
      "\n",
      "⚡ Performance Summary:\n",
      "   • Total execution time: 14.168 seconds\n",
      "   • Data loading time: 12.157 seconds\n",
      "   • File format: pickle\n",
      "   • Folds processed: 1\n",
      "   • Speed improvement: ~3.0x faster than full loading\n",
      "\n",
      "🎯 Dataset Summary for Novelty Detection:\n",
      "   • Normal training data: 2000 windows\n",
      "   • Anomaly test data: 1000 windows\n",
      "   • Window dimensions: (300, 3)\n",
      "   • Anomaly classes: [np.str_('1'), np.str_('2'), np.str_('3')]\n",
      "   • Ready for: LSTM Autoencoder training and novelty detection\n",
      "\n",
      "💡 Optimization Notes:\n",
      "   • Sampling enabled for faster processing\n",
      "   • To use full dataset: Set ENABLE_SAMPLING = False\n",
      "   • To use all folds: Set USE_SINGLE_FOLD = False\n",
      "✅ (176367 windows)\n",
      "      📊 Current totals: 2000 normal, 1000 anomaly\n",
      "      🎯 Sampling limits reached - stopping early\n",
      "   🎯 Sampling complete - sufficient data collected\n",
      "\n",
      "✅ Successfully loaded and separated windowed data!\n",
      "💚 Normal operation windows (class 0): 2000\n",
      "🔴 Anomaly windows (classes 1-9): 1000\n",
      "⚡ Loading time: 12.157 seconds\n",
      "📁 Files processed: 1\n",
      "\n",
      "📋 Processing sample windows... ✅\n",
      "\n",
      "🪟 Sample Normal Window (Window #1):\n",
      "   • Shape: (300, 3)\n",
      "   • Class: 0 (Normal Operation)\n",
      "   • Features: ['P-TPT_scaled', 'T-TPT_scaled', 'class']\n",
      "\n",
      "📊 Normal Operation Data (Class 0):\n",
      "   • Total windows: 2000\n",
      "   • Will be used for: Autoencoder training\n",
      "\n",
      "📊 Anomaly Data (Classes 1-9):\n",
      "   • Class 1: 513 windows\n",
      "   • Class 2: 371 windows\n",
      "   • Class 3: 116 windows\n",
      "   • Total anomaly windows: 1000\n",
      "   • Will be used for: Anomaly detection testing\n",
      "\n",
      "⚡ Performance Summary:\n",
      "   • Total execution time: 14.168 seconds\n",
      "   • Data loading time: 12.157 seconds\n",
      "   • File format: pickle\n",
      "   • Folds processed: 1\n",
      "   • Speed improvement: ~3.0x faster than full loading\n",
      "\n",
      "🎯 Dataset Summary for Novelty Detection:\n",
      "   • Normal training data: 2000 windows\n",
      "   • Anomaly test data: 1000 windows\n",
      "   • Window dimensions: (300, 3)\n",
      "   • Anomaly classes: [np.str_('1'), np.str_('2'), np.str_('3')]\n",
      "   • Ready for: LSTM Autoencoder training and novelty detection\n",
      "\n",
      "💡 Optimization Notes:\n",
      "   • Sampling enabled for faster processing\n",
      "   • To use full dataset: Set ENABLE_SAMPLING = False\n",
      "   • To use all folds: Set USE_SINGLE_FOLD = False\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# OPTIMIZED LOADING: 3W DATASET FOR UNSUPERVISED NOVELTY DETECTION\n",
    "# ============================================================\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"🤖 Optimized Loading: 3W Dataset for Autoencoder Novelty Detection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Import data loading utilities\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "print(\"📦 Importing modules...\", end=\" \")\n",
    "from src.data_persistence import DataPersistence\n",
    "from src import config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"✅\")\n",
    "\n",
    "# ============================================================\n",
    "# OPTIMIZATION SETTINGS - ADJUST FOR SPEED vs COMPLETENESS\n",
    "# ============================================================\n",
    "USE_SINGLE_FOLD = (\n",
    "    True  # True: Fast loading (one fold), False: Complete dataset (all folds)\n",
    ")\n",
    "TARGET_FOLD = \"fold_1\"  # Which fold to use for single fold loading\n",
    "MAX_NORMAL_SAMPLES = 2000  # Limit normal samples for faster processing\n",
    "MAX_ANOMALY_SAMPLES = 1000  # Limit anomaly samples for faster processing\n",
    "ENABLE_SAMPLING = True  # True: Apply sampling limits, False: Load all available data\n",
    "\n",
    "print(f\"⚙️ Optimization Settings:\")\n",
    "print(f\"   • Single fold loading: {USE_SINGLE_FOLD}\")\n",
    "if USE_SINGLE_FOLD:\n",
    "    print(f\"   • Target fold: {TARGET_FOLD}\")\n",
    "print(f\"   • Sampling enabled: {ENABLE_SAMPLING}\")\n",
    "if ENABLE_SAMPLING:\n",
    "    print(f\"   • Max normal samples: {MAX_NORMAL_SAMPLES}\")\n",
    "    print(f\"   • Max anomaly samples: {MAX_ANOMALY_SAMPLES}\")\n",
    "\n",
    "try:\n",
    "    print(f\"\\n📂 Initializing data persistence...\", end=\" \")\n",
    "    persistence = DataPersistence(base_dir=config.PROCESSED_DATA_DIR, verbose=False)\n",
    "    print(\"✅\")\n",
    "\n",
    "    print(f\"⚡ Using format: {config.SAVE_FORMAT} for maximum speed\")\n",
    "\n",
    "    # Check if windowed directory exists\n",
    "    windowed_dir = os.path.join(persistence.cv_splits_dir, \"windowed\")\n",
    "    print(f\"📁 Checking windowed directory: {windowed_dir}...\", end=\" \")\n",
    "\n",
    "    if not os.path.exists(windowed_dir):\n",
    "        print(\"❌\")\n",
    "        print(\n",
    "            \"❌ No windowed data directory found. Please run Data Treatment notebook first to generate windowed time series data.\"\n",
    "        )\n",
    "        raise FileNotFoundError(\"Windowed data directory not found\")\n",
    "    else:\n",
    "        print(\"✅\")\n",
    "\n",
    "        # Look for fold directories\n",
    "        print(\"🔍 Looking for fold directories...\", end=\" \")\n",
    "        fold_dirs = [\n",
    "            d\n",
    "            for d in os.listdir(windowed_dir)\n",
    "            if d.startswith(\"fold_\") and os.path.isdir(os.path.join(windowed_dir, d))\n",
    "        ]\n",
    "        fold_dirs.sort()\n",
    "        print(f\"✅ Found {len(fold_dirs)} folds: {fold_dirs}\")\n",
    "\n",
    "        if not fold_dirs:\n",
    "            print(\"❌ No fold directories found in windowed data.\")\n",
    "            raise FileNotFoundError(\"No fold directories found\")\n",
    "\n",
    "        # Determine which folds to process\n",
    "        if USE_SINGLE_FOLD:\n",
    "            if TARGET_FOLD in fold_dirs:\n",
    "                process_folds = [TARGET_FOLD]\n",
    "                print(f\"🎯 Using single fold: {TARGET_FOLD} for fast loading\")\n",
    "            else:\n",
    "                process_folds = [fold_dirs[0]]  # Use first available fold\n",
    "                print(\n",
    "                    f\"⚠️ Target fold '{TARGET_FOLD}' not found, using: {process_folds[0]}\"\n",
    "                )\n",
    "        else:\n",
    "            process_folds = fold_dirs\n",
    "            print(f\"📊 Using all {len(fold_dirs)} folds for complete dataset\")\n",
    "\n",
    "        # Separate data containers for normal (class 0) and anomaly (classes 1-9) data\n",
    "        normal_windows = []  # Class 0 for autoencoder training\n",
    "        normal_classes = []\n",
    "        anomaly_windows = []  # Classes 1-9 for anomaly testing\n",
    "        anomaly_classes = []\n",
    "\n",
    "        load_start = time.time()\n",
    "        total_files_processed = 0\n",
    "\n",
    "        for fold_idx, fold_name in enumerate(process_folds):\n",
    "            fold_path = os.path.join(windowed_dir, fold_name)\n",
    "\n",
    "            print(\n",
    "                f\"\\n📁 Processing {fold_name} ({fold_idx + 1}/{len(process_folds)})...\"\n",
    "            )\n",
    "\n",
    "            # Process training and test data\n",
    "            for data_type in [\"train\", \"test\"]:\n",
    "                print(f\"   📄 Loading {data_type} data...\", end=\" \")\n",
    "\n",
    "                # Try pickle first, then parquet\n",
    "                pickle_file = os.path.join(\n",
    "                    fold_path, f\"{data_type}_windowed.{config.SAVE_FORMAT}\"\n",
    "                )\n",
    "                parquet_file = os.path.join(fold_path, f\"{data_type}_windowed.parquet\")\n",
    "\n",
    "                fold_dfs, fold_classes = [], []\n",
    "\n",
    "                if os.path.exists(pickle_file):\n",
    "                    try:\n",
    "                        fold_dfs, fold_classes = persistence._load_dataframes(\n",
    "                            pickle_file, config.SAVE_FORMAT\n",
    "                        )\n",
    "                        print(f\"✅ ({len(fold_dfs)} windows)\")\n",
    "                        total_files_processed += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Pickle error: {str(e)}\")\n",
    "                        # Try parquet as fallback\n",
    "                        if os.path.exists(parquet_file):\n",
    "                            try:\n",
    "                                fold_dfs, fold_classes = persistence._load_from_parquet(\n",
    "                                    parquet_file\n",
    "                                )\n",
    "                                print(f\"✅ Parquet fallback ({len(fold_dfs)} windows)\")\n",
    "                                total_files_processed += 1\n",
    "                            except Exception as e2:\n",
    "                                print(f\"❌ Parquet fallback failed: {str(e2)}\")\n",
    "\n",
    "                elif os.path.exists(parquet_file):\n",
    "                    try:\n",
    "                        fold_dfs, fold_classes = persistence._load_from_parquet(\n",
    "                            parquet_file\n",
    "                        )\n",
    "                        print(f\"✅ ({len(fold_dfs)} windows)\")\n",
    "                        total_files_processed += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Parquet error: {str(e)}\")\n",
    "                else:\n",
    "                    print(\"❌ No data file found\")\n",
    "\n",
    "                # Separate normal (class 0) from anomaly (classes 1-9) data\n",
    "                for df, cls in zip(fold_dfs, fold_classes):\n",
    "                    if str(cls) == \"0\":  # Normal operation\n",
    "                        if (\n",
    "                            not ENABLE_SAMPLING\n",
    "                            or len(normal_windows) < MAX_NORMAL_SAMPLES\n",
    "                        ):\n",
    "                            normal_windows.append(df)\n",
    "                            normal_classes.append(cls)\n",
    "                    else:  # Fault conditions (anomalies)\n",
    "                        if (\n",
    "                            not ENABLE_SAMPLING\n",
    "                            or len(anomaly_windows) < MAX_ANOMALY_SAMPLES\n",
    "                        ):\n",
    "                            anomaly_windows.append(df)\n",
    "                            anomaly_classes.append(cls)\n",
    "\n",
    "                # Show progress\n",
    "                if ENABLE_SAMPLING:\n",
    "                    print(\n",
    "                        f\"      📊 Current totals: {len(normal_windows)} normal, {len(anomaly_windows)} anomaly\"\n",
    "                    )\n",
    "                    if (\n",
    "                        len(normal_windows) >= MAX_NORMAL_SAMPLES\n",
    "                        and len(anomaly_windows) >= MAX_ANOMALY_SAMPLES\n",
    "                    ):\n",
    "                        print(f\"      🎯 Sampling limits reached - stopping early\")\n",
    "                        break\n",
    "\n",
    "            # Early exit if sampling limits reached\n",
    "            if (\n",
    "                ENABLE_SAMPLING\n",
    "                and len(normal_windows) >= MAX_NORMAL_SAMPLES\n",
    "                and len(anomaly_windows) >= MAX_ANOMALY_SAMPLES\n",
    "            ):\n",
    "                print(f\"   🎯 Sampling complete - sufficient data collected\")\n",
    "                break\n",
    "\n",
    "        load_time = time.time() - load_start\n",
    "\n",
    "        if normal_windows and anomaly_windows:\n",
    "            print(f\"\\n✅ Successfully loaded and separated windowed data!\")\n",
    "            print(f\"💚 Normal operation windows (class 0): {len(normal_windows)}\")\n",
    "            print(f\"🔴 Anomaly windows (classes 1-9): {len(anomaly_windows)}\")\n",
    "            print(f\"⚡ Loading time: {load_time:.3f} seconds\")\n",
    "            print(f\"📁 Files processed: {total_files_processed}\")\n",
    "\n",
    "            # Display sample window information\n",
    "            if normal_windows:\n",
    "                print(\"\\n📋 Processing sample windows...\", end=\" \")\n",
    "                first_normal_window = normal_windows[0]\n",
    "                print(\"✅\")\n",
    "\n",
    "                print(f\"\\n🪟 Sample Normal Window (Window #1):\")\n",
    "                print(f\"   • Shape: {first_normal_window.shape}\")\n",
    "                print(f\"   • Class: {normal_classes[0]} (Normal Operation)\")\n",
    "                print(f\"   • Features: {list(first_normal_window.columns)}\")\n",
    "\n",
    "                # Show class distribution\n",
    "                print(f\"\\n📊 Normal Operation Data (Class 0):\")\n",
    "                print(f\"   • Total windows: {len(normal_windows)}\")\n",
    "                print(f\"   • Will be used for: Autoencoder training\")\n",
    "\n",
    "                print(f\"\\n📊 Anomaly Data (Classes 1-9):\")\n",
    "                anomaly_unique, anomaly_counts = np.unique(\n",
    "                    anomaly_classes, return_counts=True\n",
    "                )\n",
    "                for cls, count in zip(anomaly_unique, anomaly_counts):\n",
    "                    print(f\"   • Class {cls}: {count} windows\")\n",
    "                print(f\"   • Total anomaly windows: {len(anomaly_windows)}\")\n",
    "                print(f\"   • Will be used for: Anomaly detection testing\")\n",
    "\n",
    "                total_time = time.time() - start_time\n",
    "                print(f\"\\n⚡ Performance Summary:\")\n",
    "                print(f\"   • Total execution time: {total_time:.3f} seconds\")\n",
    "                print(f\"   • Data loading time: {load_time:.3f} seconds\")\n",
    "                print(f\"   • File format: {config.SAVE_FORMAT}\")\n",
    "                print(f\"   • Folds processed: {len(process_folds)}\")\n",
    "                print(\n",
    "                    f\"   • Speed improvement: ~{len(fold_dirs)/len(process_folds):.1f}x faster than full loading\"\n",
    "                )\n",
    "\n",
    "                print(f\"\\n🎯 Dataset Summary for Novelty Detection:\")\n",
    "                print(f\"   • Normal training data: {len(normal_windows)} windows\")\n",
    "                print(f\"   • Anomaly test data: {len(anomaly_windows)} windows\")\n",
    "                print(f\"   • Window dimensions: {first_normal_window.shape}\")\n",
    "                print(f\"   • Anomaly classes: {sorted(anomaly_unique)}\")\n",
    "                print(\n",
    "                    f\"   • Ready for: LSTM Autoencoder training and novelty detection\"\n",
    "                )\n",
    "\n",
    "                if ENABLE_SAMPLING:\n",
    "                    print(f\"\\n💡 Optimization Notes:\")\n",
    "                    print(f\"   • Sampling enabled for faster processing\")\n",
    "                    print(f\"   • To use full dataset: Set ENABLE_SAMPLING = False\")\n",
    "                    print(f\"   • To use all folds: Set USE_SINGLE_FOLD = False\")\n",
    "\n",
    "            else:\n",
    "                print(\"⚠️ No normal operation windows found\")\n",
    "\n",
    "        else:\n",
    "            print(\"⚠️ Insufficient data found for novelty detection\")\n",
    "            print(f\"   • Normal windows: {len(normal_windows)}\")\n",
    "            print(f\"   • Anomaly windows: {len(anomaly_windows)}\")\n",
    "            normal_windows = []\n",
    "            normal_classes = []\n",
    "            anomaly_windows = []\n",
    "            anomaly_classes = []\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error loading data: {str(e)}\")\n",
    "    print(f\"\\n💡 Troubleshooting:\")\n",
    "    print(f\"   1. Make sure 'Data Treatment.ipynb' ran completely\")\n",
    "    print(f\"   2. Check if windowed data was saved successfully\")\n",
    "    print(f\"   3. Verify the processed_data directory exists\")\n",
    "    print(f\"   4. Check if pickle files are corrupted\")\n",
    "    print(f\"   5. Try using parquet format instead\")\n",
    "\n",
    "    # Show detailed error information\n",
    "    import traceback\n",
    "\n",
    "    print(f\"\\n🔍 Detailed error information:\")\n",
    "    print(traceback.format_exc())\n",
    "\n",
    "    # Initialize empty variables for error case\n",
    "    normal_windows = []\n",
    "    normal_classes = []\n",
    "    anomaly_windows = []\n",
    "    anomaly_classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "229fa361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Stable LSTM Autoencoder Novelty Detection Implementation\n",
      "=================================================================\n",
      "📊 Using stable LSTM Autoencoder for novelty detection...\n",
      "🟢 Normal operation windows for training: 2000\n",
      "🔴 Anomaly windows for testing: 1000\n",
      "\n",
      "⚡ Smart Data Sampling for Training Efficiency\n",
      "==================================================\n",
      "🎯 Training optimization settings:\n",
      "   • Max normal samples for training: 1000\n",
      "   • Max anomaly samples for testing: 300\n",
      "   • Reduced for maximum stability and speed\n",
      "📊 Sampling 1000 normal windows from 2000 available...\n",
      "📊 Sampling 300 anomaly windows from 1000 available...\n",
      "\n",
      "🔧 Stable Data Preparation for LSTM Autoencoder\n",
      "==================================================\n",
      "📊 Converting normal windows to arrays... 600/1000📊 Using stable LSTM Autoencoder for novelty detection...\n",
      "🟢 Normal operation windows for training: 2000\n",
      "🔴 Anomaly windows for testing: 1000\n",
      "\n",
      "⚡ Smart Data Sampling for Training Efficiency\n",
      "==================================================\n",
      "🎯 Training optimization settings:\n",
      "   • Max normal samples for training: 1000\n",
      "   • Max anomaly samples for testing: 300\n",
      "   • Reduced for maximum stability and speed\n",
      "📊 Sampling 1000 normal windows from 2000 available...\n",
      "📊 Sampling 300 anomaly windows from 1000 available...\n",
      "\n",
      "🔧 Stable Data Preparation for LSTM Autoencoder\n",
      "==================================================\n",
      "📊 Converting normal windows to arrays... ✅ (1000 valid processed)\n",
      "📊 Converting anomaly windows to arrays... ✅ (300 valid processed)\n",
      "🔍 Validating array shapes and data quality... Expected shape: (300, 2)\n",
      "✅ Valid arrays: 1000 normal, 300 anomaly\n",
      "📊 Data quality checks:\n",
      "   • Normal data range: [0.000, 1.000]\n",
      "   • Anomaly data range: [0.000, 1.000]\n",
      "   • Normal data finite: True\n",
      "   • Anomaly data finite: True\n",
      "⚡ Data conversion completed in 0.32 seconds\n",
      "\n",
      "📐 Data shapes (after removing class column):\n",
      "   • Normal data: (1000, 300, 2)\n",
      "   • Anomaly data: (300, 300, 2)\n",
      "\n",
      "📋 LSTM Autoencoder Configuration:\n",
      "   • Time steps per window: 300\n",
      "   • Features per time step: 2 (class column removed)\n",
      "   • Normal training samples: 1000\n",
      "   • Anomaly test samples: 300\n",
      "\n",
      "📊 Additional Data Normalization for Stability\n",
      "=============================================\n",
      "📏 Enhanced data characteristics:\n",
      "   • Normal data range: [0.001, 0.999]\n",
      "   • Anomaly data range: [0.001, 0.999]\n",
      "   • Data clipped to avoid extreme values\n",
      "   • Float32 precision for stability\n",
      "\n",
      "🧠 Building Stable LSTM Autoencoder Architecture\n",
      "==================================================\n",
      "🏗️ Stable Architecture Configuration:\n",
      "   • Input shape: (300, 2)\n",
      "   • Encoder LSTM units: 32 (conservative for stability)\n",
      "   • Latent dimension: 16 (conservative for stability)\n",
      "   • Decoder LSTM units: 32\n",
      "   • Output shape: (300, 2)\n",
      "   • Dropout and gradient clipping for regularization\n",
      "📊 Converting normal windows to arrays... ✅ (1000 valid processed)\n",
      "📊 Converting anomaly windows to arrays... ✅ (300 valid processed)\n",
      "🔍 Validating array shapes and data quality... Expected shape: (300, 2)\n",
      "✅ Valid arrays: 1000 normal, 300 anomaly\n",
      "📊 Data quality checks:\n",
      "   • Normal data range: [0.000, 1.000]\n",
      "   • Anomaly data range: [0.000, 1.000]\n",
      "   • Normal data finite: True\n",
      "   • Anomaly data finite: True\n",
      "⚡ Data conversion completed in 0.32 seconds\n",
      "\n",
      "📐 Data shapes (after removing class column):\n",
      "   • Normal data: (1000, 300, 2)\n",
      "   • Anomaly data: (300, 300, 2)\n",
      "\n",
      "📋 LSTM Autoencoder Configuration:\n",
      "   • Time steps per window: 300\n",
      "   • Features per time step: 2 (class column removed)\n",
      "   • Normal training samples: 1000\n",
      "   • Anomaly test samples: 300\n",
      "\n",
      "📊 Additional Data Normalization for Stability\n",
      "=============================================\n",
      "📏 Enhanced data characteristics:\n",
      "   • Normal data range: [0.001, 0.999]\n",
      "   • Anomaly data range: [0.001, 0.999]\n",
      "   • Data clipped to avoid extreme values\n",
      "   • Float32 precision for stability\n",
      "\n",
      "🧠 Building Stable LSTM Autoencoder Architecture\n",
      "==================================================\n",
      "🏗️ Stable Architecture Configuration:\n",
      "   • Input shape: (300, 2)\n",
      "   • Encoder LSTM units: 32 (conservative for stability)\n",
      "   • Latent dimension: 16 (conservative for stability)\n",
      "   • Decoder LSTM units: 32\n",
      "   • Output shape: (300, 2)\n",
      "   • Dropout and gradient clipping for regularization\n",
      "WARNING:tensorflow:From C:\\Users\\lucas\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\lucas\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "✅ Stable LSTM Autoencoder model created\n",
      "\n",
      "📋 Model Summary:\n",
      "   • Total parameters: 11,346\n",
      "   • Trainable parameters: 11,346\n",
      "   • Model architecture optimized for stability\n",
      "   • Gradient clipping enabled (clipnorm=1.0)\n",
      "   • Conservative learning rate (0.0005)\n",
      "\n",
      "🚂 Training Stable LSTM Autoencoder on Normal Data\n",
      "=======================================================\n",
      "📊 Training split:\n",
      "   • Training samples: 800\n",
      "   • Validation samples: 200\n",
      "🚂 Starting stable training...\n",
      "   • Max epochs: 30 (conservative for stability)\n",
      "   • Batch size: 32 (conservative for stability)\n",
      "   • Early stopping patience: 10 epochs\n",
      "   • Learning rate: 0.0005 (conservative)\n",
      "   • Gradient clipping enabled\n",
      "Epoch 1/30\n",
      "✅ Stable LSTM Autoencoder model created\n",
      "\n",
      "📋 Model Summary:\n",
      "   • Total parameters: 11,346\n",
      "   • Trainable parameters: 11,346\n",
      "   • Model architecture optimized for stability\n",
      "   • Gradient clipping enabled (clipnorm=1.0)\n",
      "   • Conservative learning rate (0.0005)\n",
      "\n",
      "🚂 Training Stable LSTM Autoencoder on Normal Data\n",
      "=======================================================\n",
      "📊 Training split:\n",
      "   • Training samples: 800\n",
      "   • Validation samples: 200\n",
      "🚂 Starting stable training...\n",
      "   • Max epochs: 30 (conservative for stability)\n",
      "   • Batch size: 32 (conservative for stability)\n",
      "   • Early stopping patience: 10 epochs\n",
      "   • Learning rate: 0.0005 (conservative)\n",
      "   • Gradient clipping enabled\n",
      "Epoch 1/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 248ms/step - loss: 0.0630 - mae: 0.2101 - val_loss: 0.0612 - val_mae: 0.2014 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 248ms/step - loss: 0.0630 - mae: 0.2101 - val_loss: 0.0612 - val_mae: 0.2014 - learning_rate: 5.0000e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0545 - mae: 0.1902 - val_loss: 0.0452 - val_mae: 0.1686 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0545 - mae: 0.1902 - val_loss: 0.0452 - val_mae: 0.1686 - learning_rate: 5.0000e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0397 - mae: 0.1582 - val_loss: 0.0310 - val_mae: 0.1355 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 149ms/step - loss: 0.0397 - mae: 0.1582 - val_loss: 0.0310 - val_mae: 0.1355 - learning_rate: 5.0000e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0335 - mae: 0.1400 - val_loss: 0.0229 - val_mae: 0.1128 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0335 - mae: 0.1400 - val_loss: 0.0229 - val_mae: 0.1128 - learning_rate: 5.0000e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0335 - mae: 0.1361 - val_loss: 0.0221 - val_mae: 0.1162 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0335 - mae: 0.1361 - val_loss: 0.0221 - val_mae: 0.1162 - learning_rate: 5.0000e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0292 - mae: 0.1240 - val_loss: 0.0183 - val_mae: 0.1034 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0292 - mae: 0.1240 - val_loss: 0.0183 - val_mae: 0.1034 - learning_rate: 5.0000e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0268 - mae: 0.1192 - val_loss: 0.0173 - val_mae: 0.1007 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0268 - mae: 0.1192 - val_loss: 0.0173 - val_mae: 0.1007 - learning_rate: 5.0000e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0250 - mae: 0.1147 - val_loss: 0.0164 - val_mae: 0.0973 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0250 - mae: 0.1147 - val_loss: 0.0164 - val_mae: 0.0973 - learning_rate: 5.0000e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0263 - mae: 0.1165 - val_loss: 0.0177 - val_mae: 0.1045 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0263 - mae: 0.1165 - val_loss: 0.0177 - val_mae: 0.1045 - learning_rate: 5.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0261 - mae: 0.1139 - val_loss: 0.0174 - val_mae: 0.1033 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0261 - mae: 0.1139 - val_loss: 0.0174 - val_mae: 0.1033 - learning_rate: 5.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0298 - mae: 0.1188 - val_loss: 0.0172 - val_mae: 0.1002 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0298 - mae: 0.1188 - val_loss: 0.0172 - val_mae: 0.1002 - learning_rate: 5.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0272 - mae: 0.1165 - val_loss: 0.0179 - val_mae: 0.1074 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0272 - mae: 0.1165 - val_loss: 0.0179 - val_mae: 0.1074 - learning_rate: 5.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - loss: 0.0267 - mae: 0.1153\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0267 - mae: 0.1152 - val_loss: 0.0169 - val_mae: 0.1007 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0267 - mae: 0.1152 - val_loss: 0.0169 - val_mae: 0.1007 - learning_rate: 5.0000e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0268 - mae: 0.1144 - val_loss: 0.0178 - val_mae: 0.1061 - learning_rate: 2.5000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 159ms/step - loss: 0.0268 - mae: 0.1144 - val_loss: 0.0178 - val_mae: 0.1061 - learning_rate: 2.5000e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0277 - mae: 0.1178 - val_loss: 0.0165 - val_mae: 0.0977 - learning_rate: 2.5000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 156ms/step - loss: 0.0277 - mae: 0.1178 - val_loss: 0.0165 - val_mae: 0.0977 - learning_rate: 2.5000e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0270 - mae: 0.1157 - val_loss: 0.0167 - val_mae: 0.1005 - learning_rate: 2.5000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0270 - mae: 0.1157 - val_loss: 0.0167 - val_mae: 0.1005 - learning_rate: 2.5000e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0252 - mae: 0.1118 - val_loss: 0.0171 - val_mae: 0.1025 - learning_rate: 2.5000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0252 - mae: 0.1118 - val_loss: 0.0171 - val_mae: 0.1025 - learning_rate: 2.5000e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - loss: 0.0244 - mae: 0.1080\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0244 - mae: 0.1082 - val_loss: 0.0164 - val_mae: 0.0989 - learning_rate: 2.5000e-04\n",
      "Epoch 19/30\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0244 - mae: 0.1082 - val_loss: 0.0164 - val_mae: 0.0989 - learning_rate: 2.5000e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0268 - mae: 0.1143 - val_loss: 0.0169 - val_mae: 0.1028 - learning_rate: 1.2500e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0268 - mae: 0.1143 - val_loss: 0.0169 - val_mae: 0.1028 - learning_rate: 1.2500e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0227 - mae: 0.1069 - val_loss: 0.0162 - val_mae: 0.0994 - learning_rate: 1.2500e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 155ms/step - loss: 0.0227 - mae: 0.1069 - val_loss: 0.0162 - val_mae: 0.0994 - learning_rate: 1.2500e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0266 - mae: 0.1126 - val_loss: 0.0166 - val_mae: 0.1011 - learning_rate: 1.2500e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 153ms/step - loss: 0.0266 - mae: 0.1126 - val_loss: 0.0166 - val_mae: 0.1011 - learning_rate: 1.2500e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0264 - mae: 0.1143 - val_loss: 0.0166 - val_mae: 0.1008 - learning_rate: 1.2500e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0264 - mae: 0.1143 - val_loss: 0.0166 - val_mae: 0.1008 - learning_rate: 1.2500e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0260 - mae: 0.1131 - val_loss: 0.0168 - val_mae: 0.1014 - learning_rate: 1.2500e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 154ms/step - loss: 0.0260 - mae: 0.1131 - val_loss: 0.0168 - val_mae: 0.1014 - learning_rate: 1.2500e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0238 - mae: 0.1093 - val_loss: 0.0164 - val_mae: 0.0997 - learning_rate: 1.2500e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - loss: 0.0238 - mae: 0.1093 - val_loss: 0.0164 - val_mae: 0.0997 - learning_rate: 1.2500e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0283 - mae: 0.1152\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 0.0283 - mae: 0.1152 - val_loss: 0.0168 - val_mae: 0.1018 - learning_rate: 1.2500e-04\n",
      "Epoch 26/30\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 166ms/step - loss: 0.0283 - mae: 0.1152 - val_loss: 0.0168 - val_mae: 0.1018 - learning_rate: 1.2500e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0285 - mae: 0.1159 - val_loss: 0.0169 - val_mae: 0.1014 - learning_rate: 6.2500e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 158ms/step - loss: 0.0285 - mae: 0.1159 - val_loss: 0.0169 - val_mae: 0.1014 - learning_rate: 6.2500e-05\n",
      "Epoch 27/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 0.0272 - mae: 0.1153 - val_loss: 0.0168 - val_mae: 0.1017 - learning_rate: 6.2500e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 171ms/step - loss: 0.0272 - mae: 0.1153 - val_loss: 0.0168 - val_mae: 0.1017 - learning_rate: 6.2500e-05\n",
      "Epoch 28/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0285 - mae: 0.1165 - val_loss: 0.0165 - val_mae: 0.0994 - learning_rate: 6.2500e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - loss: 0.0285 - mae: 0.1165 - val_loss: 0.0165 - val_mae: 0.0994 - learning_rate: 6.2500e-05\n",
      "Epoch 29/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0282 - mae: 0.1167 - val_loss: 0.0168 - val_mae: 0.1008 - learning_rate: 6.2500e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 157ms/step - loss: 0.0282 - mae: 0.1167 - val_loss: 0.0168 - val_mae: 0.1008 - learning_rate: 6.2500e-05\n",
      "Epoch 30/30\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - loss: 0.0230 - mae: 0.1053\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0230 - mae: 0.1054 - val_loss: 0.0168 - val_mae: 0.1016 - learning_rate: 6.2500e-05\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 161ms/step - loss: 0.0230 - mae: 0.1054 - val_loss: 0.0168 - val_mae: 0.1016 - learning_rate: 6.2500e-05\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\n",
      "✅ Training completed in 128.86 seconds\n",
      "   • Epochs trained: 30\n",
      "   ✅ Training successful - no NaN values\n",
      "   • Final training loss: 0.023966\n",
      "   • Final validation loss: 0.016760\n",
      "\n",
      "✅ Training completed in 128.86 seconds\n",
      "   • Epochs trained: 30\n",
      "   ✅ Training successful - no NaN values\n",
      "   • Final training loss: 0.023966\n",
      "   • Final validation loss: 0.016760\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Training Summary:\n",
      "   ✅ Model successfully trained on normal operation data\n",
      "   ✅ Training time: 128.86 seconds\n",
      "   ✅ Stable architecture with numerical safeguards\n",
      "   ✅ Ready for anomaly detection evaluation\n",
      "   ✅ No NaN values encountered during training\n",
      "\n",
      "⚡ Stability Optimizations Applied:\n",
      "   • Conservative model architecture (32 LSTM units)\n",
      "   • Lower learning rate (0.0005)\n",
      "   • Gradient clipping (clipnorm=1.0)\n",
      "   • Tanh activations for stability\n",
      "   • Data clipping to avoid extreme values\n",
      "   • Careful weight initialization\n",
      "   • Enhanced numerical checks\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPORT REQUIRED LIBRARIES AND MODULES\n",
    "# ============================================================\n",
    "\n",
    "print(\"🤖 LSTM Autoencoder for Anomaly Detection\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Import our custom modules\n",
    "from src.autoencoder_models import StableLSTMAutoencoder\n",
    "from src.unsupervised_preprocessing import UnsupervisedDataPreprocessor\n",
    "from src.anomaly_detection import AnomalyDetector, visualize_latent_space\n",
    "\n",
    "# Set TensorFlow to avoid NaN issues\n",
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "# Check if we have loaded data from previous cell\n",
    "if (\n",
    "    \"normal_windows\" in locals()\n",
    "    and normal_windows is not None\n",
    "    and len(normal_windows) > 0\n",
    "    and \"anomaly_windows\" in locals()\n",
    "    and anomaly_windows is not None\n",
    "    and len(anomaly_windows) > 0\n",
    "):\n",
    "\n",
    "    print(\"✅ Data available for processing\")\n",
    "    print(f\"🟢 Normal operation windows: {len(normal_windows)}\")\n",
    "    print(f\"🔴 Anomaly windows: {len(anomaly_windows)}\")\n",
    "    data_ready = True\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"❌ No data available. Please run the previous cell first to load normal and anomaly data.\"\n",
    "    )\n",
    "    data_ready = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647600ad",
   "metadata": {},
   "source": [
    "## 🧩 Modular LSTM Autoencoder Implementation\n",
    "\n",
    "This section implements a **stable LSTM autoencoder** for anomaly detection using a **modular approach**. The code has been organized into reusable components in the `src/` directory:\n",
    "\n",
    "### 📦 New Modules Created:\n",
    "\n",
    "1. **`autoencoder_models.py`** - Contains the `StableLSTMAutoencoder` class with:\n",
    "   - Stable architecture with gradient clipping\n",
    "   - Conservative hyperparameters for numerical stability\n",
    "   - Built-in training and prediction methods\n",
    "\n",
    "2. **`unsupervised_preprocessing.py`** - Contains the `UnsupervisedDataPreprocessor` class with:\n",
    "   - Smart data sampling for training efficiency\n",
    "   - Robust data validation and conversion\n",
    "   - Numerical stability enhancements\n",
    "\n",
    "3. **`anomaly_detection.py`** - Contains the `AnomalyDetector` class with:\n",
    "   - Reconstruction error computation\n",
    "   - Threshold determination methods\n",
    "   - Performance evaluation and visualization\n",
    "\n",
    "### 🎯 Benefits of This Approach:\n",
    "\n",
    "- **Modularity**: Each component has a single responsibility\n",
    "- **Reusability**: Classes can be used in other projects\n",
    "- **Maintainability**: Easier to debug and modify individual components\n",
    "- **Stability**: Enhanced numerical safeguards and error handling\n",
    "- **Clarity**: Notebook cells are focused and easier to understand\n",
    "\n",
    "### 🚀 Usage Pattern:\n",
    "\n",
    "The following cells demonstrate the complete pipeline from data preprocessing through model training to anomaly detection evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78e6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA PREPROCESSING AND SAMPLING\n",
    "# ============================================================\n",
    "\n",
    "if data_ready:\n",
    "    print(\"🔧 Data Preprocessing Pipeline\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    # Initialize data preprocessor with conservative settings for stability\n",
    "    preprocessor = UnsupervisedDataPreprocessor(\n",
    "        max_training_samples=1000,  # Reduced for stability\n",
    "        max_anomaly_samples=300,  # Reduced for stability\n",
    "        random_seed=42,\n",
    "    )\n",
    "\n",
    "    # Run the complete preprocessing pipeline\n",
    "    normal_scaled, anomaly_scaled, data_info = preprocessor.prepare_full_pipeline(\n",
    "        normal_windows, anomaly_windows\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅ Data preprocessing completed successfully!\")\n",
    "    print(f\"📋 Final Configuration:\")\n",
    "    print(f\"   • Time steps per window: {data_info['time_steps']}\")\n",
    "    print(\n",
    "        f\"   • Features per time step: {data_info['n_features']} (class column removed)\"\n",
    "    )\n",
    "    print(f\"   • Normal training samples: {data_info['n_normal_samples']}\")\n",
    "    print(f\"   • Anomaly test samples: {data_info['n_anomaly_samples']}\")\n",
    "\n",
    "    preprocessing_complete = True\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot proceed with preprocessing - no data available\")\n",
    "    preprocessing_complete = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BUILD AND TRAIN LSTM AUTOENCODER\n",
    "# ============================================================\n",
    "\n",
    "if preprocessing_complete:\n",
    "    print(\"🧠 Building and Training LSTM Autoencoder\")\n",
    "    print(\"=\" * 45)\n",
    "\n",
    "    # Initialize the autoencoder with conservative parameters for stability\n",
    "    autoencoder = StableLSTMAutoencoder(\n",
    "        time_steps=data_info[\"time_steps\"],\n",
    "        n_features=data_info[\"n_features\"],\n",
    "        latent_dim=16,  # Conservative for stability\n",
    "        lstm_units=32,  # Conservative for stability\n",
    "    )\n",
    "\n",
    "    # Build the model\n",
    "    model = autoencoder.build_model()\n",
    "\n",
    "    # Split normal data into train/validation (80/20 split)\n",
    "    split_idx = int(0.8 * len(normal_scaled))\n",
    "    train_normal = normal_scaled[:split_idx]\n",
    "    val_normal = normal_scaled[split_idx:]\n",
    "\n",
    "    print(f\"\\n📊 Training Data Split:\")\n",
    "    print(f\"   • Training samples: {len(train_normal)}\")\n",
    "    print(f\"   • Validation samples: {len(val_normal)}\")\n",
    "\n",
    "    # Train the autoencoder\n",
    "    print(f\"\\n🚂 Starting Training...\")\n",
    "    training_start = time.time()\n",
    "\n",
    "    training_success = autoencoder.train(\n",
    "        train_data=train_normal,\n",
    "        val_data=val_normal,\n",
    "        epochs=30,  # Conservative for stability\n",
    "        batch_size=32,  # Conservative for stability\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    training_time = time.time() - training_start\n",
    "    print(f\"\\n⏱️ Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "    if training_success:\n",
    "        print(\"✅ Model trained successfully - ready for anomaly detection!\")\n",
    "        model_ready = True\n",
    "    else:\n",
    "        print(\"❌ Training failed - check for numerical stability issues\")\n",
    "        model_ready = False\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot build model - preprocessing not completed\")\n",
    "    model_ready = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1072a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAINING VISUALIZATION\n",
    "# ============================================================\n",
    "\n",
    "if model_ready and autoencoder.history is not None:\n",
    "    print(\"📊 Training History Visualization\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    history = autoencoder.history.history\n",
    "\n",
    "    # Create training plots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history[\"loss\"], label=\"Training Loss\", linewidth=2, color=\"blue\")\n",
    "    plt.plot(history[\"val_loss\"], label=\"Validation Loss\", linewidth=2, color=\"orange\")\n",
    "    plt.title(\"Model Loss During Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # MAE plot\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history[\"mae\"], label=\"Training MAE\", linewidth=2, color=\"blue\")\n",
    "    plt.plot(history[\"val_mae\"], label=\"Validation MAE\", linewidth=2, color=\"orange\")\n",
    "    plt.title(\"Model MAE During Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Absolute Error\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    # Learning rate plot (if available)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if \"lr\" in history:\n",
    "        plt.plot(history[\"lr\"], label=\"Learning Rate\", linewidth=2, color=\"green\")\n",
    "        plt.title(\"Learning Rate Schedule\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Learning Rate\")\n",
    "        plt.yscale(\"log\")\n",
    "    else:\n",
    "        plt.text(\n",
    "            0.5,\n",
    "            0.5,\n",
    "            \"Learning Rate\\nHistory\\nNot Available\",\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            transform=plt.gca().transAxes,\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"lightgray\"),\n",
    "        )\n",
    "        plt.title(\"Learning Rate Schedule\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print training summary\n",
    "    final_train_loss = history[\"loss\"][-1]\n",
    "    final_val_loss = history[\"val_loss\"][-1]\n",
    "    epochs_trained = len(history[\"loss\"])\n",
    "\n",
    "    print(f\"\\n📋 Training Summary:\")\n",
    "    print(f\"   • Epochs trained: {epochs_trained}\")\n",
    "    print(f\"   • Final training loss: {final_train_loss:.6f}\")\n",
    "    print(f\"   • Final validation loss: {final_val_loss:.6f}\")\n",
    "    print(f\"   • Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "    if final_val_loss < final_train_loss * 1.5:\n",
    "        print(\"   ✅ No significant overfitting detected\")\n",
    "    else:\n",
    "        print(\"   ⚠️ Possible overfitting - validation loss higher than expected\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No training history available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ANOMALY DETECTION AND EVALUATION\n",
    "# ============================================================\n",
    "\n",
    "if model_ready:\n",
    "    print(\"🔍 Anomaly Detection and Evaluation\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    # Initialize anomaly detector\n",
    "    detector = AnomalyDetector()\n",
    "\n",
    "    # Compute reconstruction errors\n",
    "    normal_errors, anomaly_errors = detector.compute_reconstruction_errors(\n",
    "        autoencoder=autoencoder, normal_data=normal_scaled, anomaly_data=anomaly_scaled\n",
    "    )\n",
    "\n",
    "    # Determine threshold using 95th percentile of normal errors\n",
    "    threshold = detector.determine_threshold(method=\"percentile\", percentile=95)\n",
    "\n",
    "    # Evaluate detection performance\n",
    "    metrics = detector.evaluate_detection()\n",
    "\n",
    "    print(f\"\\n🎯 Anomaly Detection Results:\")\n",
    "    print(f\"   • Threshold: {threshold:.6f}\")\n",
    "    print(f\"   • Normal accuracy: {metrics['normal_accuracy']:.3f}\")\n",
    "    print(f\"   • Anomaly accuracy: {metrics['anomaly_accuracy']:.3f}\")\n",
    "    print(f\"   • Overall accuracy: {metrics['overall_accuracy']:.3f}\")\n",
    "\n",
    "    detection_complete = True\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot perform anomaly detection - model not ready\")\n",
    "    detection_complete = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78676a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RESULTS VISUALIZATION\n",
    "# ============================================================\n",
    "\n",
    "if detection_complete:\n",
    "    print(\"📊 Comprehensive Results Visualization\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    # Plot reconstruction error distributions\n",
    "    print(\"📈 Plotting reconstruction error distributions...\")\n",
    "    detector.plot_error_distributions(figsize=(15, 10))\n",
    "\n",
    "    # Plot ROC curve\n",
    "    print(\"📈 Plotting ROC curve...\")\n",
    "    roc_auc = detector.plot_roc_curve()\n",
    "\n",
    "    print(f\"\\n📊 Visualization Summary:\")\n",
    "    print(f\"   ✅ Error distribution plots generated\")\n",
    "    print(f\"   ✅ ROC curve generated (AUC: {roc_auc:.3f})\")\n",
    "    print(f\"   ✅ Comprehensive analysis completed\")\n",
    "\n",
    "    if roc_auc > 0.8:\n",
    "        print(f\"   🎉 Excellent anomaly detection performance!\")\n",
    "    elif roc_auc > 0.7:\n",
    "        print(f\"   👍 Good anomaly detection performance\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ Consider tuning model parameters for better performance\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot generate visualizations - detection not completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f25ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LATENT SPACE VISUALIZATION (OPTIONAL)\n",
    "# ============================================================\n",
    "\n",
    "if detection_complete:\n",
    "    print(\"🎨 Advanced Analysis: Latent Space Visualization\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        # Visualize latent space with t-SNE\n",
    "        visualize_latent_space(\n",
    "            autoencoder=autoencoder,\n",
    "            normal_data=normal_scaled,\n",
    "            anomaly_data=anomaly_scaled,\n",
    "            n_samples=500,  # Sample for faster computation\n",
    "        )\n",
    "\n",
    "        print(f\"\\n✅ Latent space visualization completed\")\n",
    "        print(f\"   • This visualization shows how the autoencoder learns to\")\n",
    "        print(f\"     separate normal and anomalous patterns in its internal\")\n",
    "        print(f\"     latent representation\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Latent space visualization failed: {str(e)}\")\n",
    "        print(f\"   • This is optional and doesn't affect the main analysis\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Cannot visualize latent space - detection not completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d414dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Reconstruction Error Analysis and Anomaly Threshold\n",
      "============================================================\n",
      "\n",
      "📊 Computing Reconstruction Errors\n",
      "========================================\n",
      "🔵 Computing reconstruction errors for normal data... ✅\n",
      "🔴 Computing reconstruction errors for anomaly data... ✅\n",
      "🔴 Computing reconstruction errors for anomaly data... ✅\n",
      "\n",
      "📈 Statistical Threshold Determination\n",
      "==========================================\n",
      "📊 Normal Data Reconstruction Error Statistics:\n",
      "   • Mean error: 0.014571\n",
      "   • Standard deviation: 0.016475\n",
      "   • Min error: 0.000585\n",
      "   • Max error: 0.194340\n",
      "\n",
      "🎯 Anomaly Detection Threshold:\n",
      "   • Threshold (μ + 3σ): 0.047522\n",
      "   • Confidence level: 99.7%\n",
      "   • Normal samples above threshold: 49 / 1000\n",
      "   • Normal false positive rate: 4.90%\n",
      "\n",
      "🔴 Anomaly Detection Performance:\n",
      "   • Anomaly samples above threshold: 125 / 300\n",
      "   • Anomaly detection rate: 41.67%\n",
      "\n",
      "📊 Anomaly Detection by Class:\n",
      "✅\n",
      "\n",
      "📈 Statistical Threshold Determination\n",
      "==========================================\n",
      "📊 Normal Data Reconstruction Error Statistics:\n",
      "   • Mean error: 0.014571\n",
      "   • Standard deviation: 0.016475\n",
      "   • Min error: 0.000585\n",
      "   • Max error: 0.194340\n",
      "\n",
      "🎯 Anomaly Detection Threshold:\n",
      "   • Threshold (μ + 3σ): 0.047522\n",
      "   • Confidence level: 99.7%\n",
      "   • Normal samples above threshold: 49 / 1000\n",
      "   • Normal false positive rate: 4.90%\n",
      "\n",
      "🔴 Anomaly Detection Performance:\n",
      "   • Anomaly samples above threshold: 125 / 300\n",
      "   • Anomaly detection rate: 41.67%\n",
      "\n",
      "📊 Anomaly Detection by Class:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along axis 0; size of axis is 300 but size of corresponding boolean axis is 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m unique_anomaly_classes:\n\u001b[32m     68\u001b[39m     cls_mask = np.array(anomaly_classes) == \u001b[38;5;28mcls\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     cls_errors = \u001b[43manomaly_errors\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcls_mask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     70\u001b[39m     cls_detected = np.sum(cls_errors > threshold)\n\u001b[32m     71\u001b[39m     cls_total = \u001b[38;5;28mlen\u001b[39m(cls_errors)\n",
      "\u001b[31mIndexError\u001b[39m: boolean index did not match indexed array along axis 0; size of axis is 300 but size of corresponding boolean axis is 1000"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SUMMARY AND NEXT STEPS\n",
    "# ============================================================\n",
    "\n",
    "if detection_complete:\n",
    "    print(\" Unsupervised Learning Summary\")\n",
    "    print(\"=\" * 35)\n",
    "\n",
    "    print(f\"✅ Complete LSTM Autoencoder Pipeline Executed:\")\n",
    "    print(\n",
    "        f\"   • Data preprocessing: {data_info['n_normal_samples']} normal, {data_info['n_anomaly_samples']} anomaly samples\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   • Model architecture: {autoencoder.lstm_units} LSTM units, {autoencoder.latent_dim} latent dimensions\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   • Training: {len(autoencoder.history.history['loss'])} epochs, final loss: {autoencoder.history.history['loss'][-1]:.6f}\"\n",
    "    )\n",
    "    print(f\"   • Anomaly detection: {metrics['overall_accuracy']:.3f} overall accuracy\")\n",
    "    print(f\"   • ROC AUC: {roc_auc:.3f}\")\n",
    "\n",
    "    print(f\"\\n🎓 Key Learning Outcomes:\")\n",
    "    print(f\"   • LSTM autoencoders can learn normal operation patterns\")\n",
    "    print(f\"   • Reconstruction errors effectively identify anomalies\")\n",
    "    print(f\"   • Threshold selection critically impacts detection performance\")\n",
    "    print(f\"   • Latent space visualization reveals learned representations\")\n",
    "\n",
    "    print(f\"\\n🚀 Next Steps for Advanced Analysis:\")\n",
    "    print(f\"   • Experiment with different autoencoder architectures\")\n",
    "    print(f\"   • Try variational autoencoders (VAEs) for uncertainty quantification\")\n",
    "    print(f\"   • Implement online anomaly detection for real-time monitoring\")\n",
    "    print(\n",
    "        f\"   • Compare with other unsupervised methods (Isolation Forest, One-Class SVM)\"\n",
    "    )\n",
    "\n",
    "    # Store final results for potential further analysis\n",
    "    final_results = {\n",
    "        \"autoencoder\": autoencoder,\n",
    "        \"detector\": detector,\n",
    "        \"metrics\": metrics,\n",
    "        \"data_info\": data_info,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"normal_scaled\": normal_scaled,\n",
    "        \"anomaly_scaled\": anomaly_scaled,\n",
    "    }\n",
    "\n",
    "    print(f\"\\n💾 Results stored in 'final_results' for further analysis\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Analysis incomplete - please run all previous cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ADVANCED LATENT SPACE ANALYSIS (OPTIONAL)\n",
    "# ============================================================\n",
    "\n",
    "print(\"🌌 Advanced Latent Space Analysis\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "if \"final_results\" in locals() and final_results is not None:\n",
    "\n",
    "    # Extract components from results\n",
    "    autoencoder_model = final_results[\"autoencoder\"]\n",
    "    normal_data = final_results[\"normal_scaled\"]\n",
    "    anomaly_data = final_results[\"anomaly_scaled\"]\n",
    "\n",
    "    print(\"🧠 Extracting and Analyzing Latent Representations\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        # Create encoder model to extract latent representations\n",
    "        encoder_input = autoencoder_model.model.input\n",
    "        encoder_output = autoencoder_model.model.get_layer(\"latent\").output\n",
    "        encoder = tf.keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "\n",
    "        # Extract latent representations\n",
    "        print(\"🔵 Computing latent representations for normal data...\")\n",
    "        normal_latent = encoder.predict(\n",
    "            normal_data[:500], verbose=0\n",
    "        )  # Sample for efficiency\n",
    "\n",
    "        print(\"🔴 Computing latent representations for anomaly data...\")\n",
    "        anomaly_latent = encoder.predict(\n",
    "            anomaly_data[:200], verbose=0\n",
    "        )  # Sample for efficiency\n",
    "\n",
    "        print(f\"📊 Latent space analysis:\")\n",
    "        print(f\"   • Normal latent shape: {normal_latent.shape}\")\n",
    "        print(f\"   • Anomaly latent shape: {anomaly_latent.shape}\")\n",
    "        print(f\"   • Latent dimension: {normal_latent.shape[1]}\")\n",
    "\n",
    "        # Combine for analysis\n",
    "        all_latent = np.vstack([normal_latent, anomaly_latent])\n",
    "        labels = np.concatenate(\n",
    "            [\n",
    "                np.zeros(len(normal_latent)),  # 0 for normal\n",
    "                np.ones(len(anomaly_latent)),  # 1 for anomaly\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Latent space statistics\n",
    "        normal_mean = np.mean(normal_latent, axis=0)\n",
    "        anomaly_mean = np.mean(anomaly_latent, axis=0)\n",
    "        latent_separation = np.linalg.norm(normal_mean - anomaly_mean)\n",
    "\n",
    "        print(f\"\\n Latent Space Statistics:\")\n",
    "        print(f\"   • Normal latent mean magnitude: {np.linalg.norm(normal_mean):.3f}\")\n",
    "        print(f\"   • Anomaly latent mean magnitude: {np.linalg.norm(anomaly_mean):.3f}\")\n",
    "        print(f\"   • Mean separation distance: {latent_separation:.3f}\")\n",
    "\n",
    "        # Simple 2D visualization if latent dimension allows\n",
    "        if normal_latent.shape[1] >= 2:\n",
    "            plt.figure(figsize=(12, 5))\n",
    "\n",
    "            # Plot first two latent dimensions\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.scatter(\n",
    "                normal_latent[:, 0],\n",
    "                normal_latent[:, 1],\n",
    "                alpha=0.6,\n",
    "                label=\"Normal\",\n",
    "                color=\"blue\",\n",
    "                s=20,\n",
    "            )\n",
    "            plt.scatter(\n",
    "                anomaly_latent[:, 0],\n",
    "                anomaly_latent[:, 1],\n",
    "                alpha=0.6,\n",
    "                label=\"Anomaly\",\n",
    "                color=\"red\",\n",
    "                s=20,\n",
    "            )\n",
    "            plt.xlabel(\"Latent Dimension 1\")\n",
    "            plt.ylabel(\"Latent Dimension 2\")\n",
    "            plt.title(\"Latent Space (First 2 Dimensions)\")\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            # Plot latent dimension distributions\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.hist(\n",
    "                normal_latent[:, 0],\n",
    "                bins=30,\n",
    "                alpha=0.7,\n",
    "                label=\"Normal (Dim 1)\",\n",
    "                color=\"blue\",\n",
    "                density=True,\n",
    "            )\n",
    "            plt.hist(\n",
    "                anomaly_latent[:, 0],\n",
    "                bins=30,\n",
    "                alpha=0.7,\n",
    "                label=\"Anomaly (Dim 1)\",\n",
    "                color=\"red\",\n",
    "                density=True,\n",
    "            )\n",
    "            plt.xlabel(\"Latent Value\")\n",
    "            plt.ylabel(\"Density\")\n",
    "            plt.title(\"Latent Dimension 1 Distribution\")\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        print(f\"\\n✅ Advanced latent space analysis completed\")\n",
    "        print(f\"   • The latent space shows how the autoencoder compresses\")\n",
    "        print(f\"     time series data into a lower-dimensional representation\")\n",
    "        print(f\"   • Separation in latent space indicates learned differences\")\n",
    "        print(f\"     between normal and anomalous patterns\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Advanced latent analysis failed: {str(e)}\")\n",
    "        print(f\"   • This is optional and doesn't affect the main results\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No results available for latent space analysis\")\n",
    "    print(\"   • Please run all previous cells to generate results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c07b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌳 Individual Algorithm Training Example\n",
      "==================================================\n",
      "📊 Comprehensive classification already completed above!\n",
      "🔍 Here's how to access individual algorithm results:\n",
      "\n",
      "🌳 Tree-Based Models Performance:\n",
      "----------------------------------------\n",
      "Decision Tree:\n",
      "   • Training Accuracy: 0.657\n",
      "   • Test Accuracy: 0.389\n",
      "   • Training Time: 3.906s\n",
      "\n",
      "Random Forest:\n",
      "   • Training Accuracy: 0.866\n",
      "   • Test Accuracy: 0.531\n",
      "   • Training Time: 2.421s\n",
      "   • Top 5 Most Important Features:\n",
      "     1. Feature 593: 0.0087\n",
      "     2. Feature 577: 0.0072\n",
      "     3. Feature 581: 0.0065\n",
      "     4. Feature 595: 0.0063\n",
      "     5. Feature 569: 0.0062\n",
      "\n",
      "💡 To train individual algorithms separately:\n",
      "   1. Use supervised_classifier.prepare_data() to get X_train, y_train, X_test, y_test\n",
      "   2. Call supervised_classifier.train_decision_trees(X_train, y_train, X_test, y_test)\n",
      "   3. Or use supervised_classifier.train_svm() or train_neural_networks()\n",
      "\n",
      "🔧 Example: Training only Decision Trees individually\n",
      "(This would be useful if you only want specific algorithms)\n",
      "✅ Data preparation, class balancing, and augmentation already handled by module\n",
      "✅ All models already trained - see comprehensive results above\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# LSTM AUTOENCODER FOR NOVELTY DETECTION\n",
    "# ============================================================\n",
    "\n",
    "print(\"🤖 LSTM Autoencoder Novelty Detection Implementation\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Check if we have loaded data from previous cell\n",
    "if (\n",
    "    \"normal_windows\" in locals()\n",
    "    and normal_windows is not None\n",
    "    and len(normal_windows) > 0\n",
    "    and \"anomaly_windows\" in locals()\n",
    "    and anomaly_windows is not None\n",
    "    and len(anomaly_windows) > 0\n",
    "):\n",
    "\n",
    "    # Import required libraries\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import (\n",
    "        Input,\n",
    "        LSTM,\n",
    "        Dense,\n",
    "        RepeatVector,\n",
    "        TimeDistributed,\n",
    "        Dropout,\n",
    "    )\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    from sklearn.manifold import TSNE\n",
    "    import matplotlib.pyplot as plt\n",
    "    import time\n",
    "\n",
    "    print(\"📊 Using optimized LSTM Autoencoder for novelty detection...\")\n",
    "    print(f\"🟢 Normal operation windows for training: {len(normal_windows)}\")\n",
    "    print(f\"🔴 Anomaly windows for testing: {len(anomaly_windows)}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # SMART DATA SAMPLING FOR FASTER TRAINING\n",
    "    # ============================================================\n",
    "    print(\"\\n⚡ Smart Data Sampling for Training Efficiency\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Use subset for faster training (configurable)\n",
    "    MAX_TRAINING_SAMPLES = 1500  # Reduced for faster training\n",
    "    MAX_ANOMALY_SAMPLES = 500  # Reduced for faster evaluation\n",
    "\n",
    "    print(f\"🎯 Training optimization settings:\")\n",
    "    print(f\"   • Max normal samples for training: {MAX_TRAINING_SAMPLES}\")\n",
    "    print(f\"   • Max anomaly samples for testing: {MAX_ANOMALY_SAMPLES}\")\n",
    "    print(f\"   • This ensures reasonable training time with good performance\")\n",
    "\n",
    "    # Sample normal data for training\n",
    "    if len(normal_windows) > MAX_TRAINING_SAMPLES:\n",
    "        print(\n",
    "            f\"📊 Sampling {MAX_TRAINING_SAMPLES} normal windows from {len(normal_windows)} available...\"\n",
    "        )\n",
    "        # Use random sampling to get diverse examples\n",
    "        import random\n",
    "\n",
    "        sampled_indices = random.sample(\n",
    "            range(len(normal_windows)), MAX_TRAINING_SAMPLES\n",
    "        )\n",
    "        sampled_normal_windows = [normal_windows[i] for i in sampled_indices]\n",
    "    else:\n",
    "        print(f\"📊 Using all {len(normal_windows)} normal windows...\")\n",
    "        sampled_normal_windows = normal_windows\n",
    "\n",
    "    # Sample anomaly data for testing\n",
    "    if len(anomaly_windows) > MAX_ANOMALY_SAMPLES:\n",
    "        print(\n",
    "            f\"📊 Sampling {MAX_ANOMALY_SAMPLES} anomaly windows from {len(anomaly_windows)} available...\"\n",
    "        )\n",
    "        sampled_indices = random.sample(\n",
    "            range(len(anomaly_windows)), MAX_ANOMALY_SAMPLES\n",
    "        )\n",
    "        sampled_anomaly_windows = [anomaly_windows[i] for i in sampled_indices]\n",
    "    else:\n",
    "        print(f\"📊 Using all {len(anomaly_windows)} anomaly windows...\")\n",
    "        sampled_anomaly_windows = anomaly_windows\n",
    "\n",
    "    # ============================================================\n",
    "    # DATA PREPARATION WITH PROGRESS FEEDBACK\n",
    "    # ============================================================\n",
    "    print(\"\\n🔧 Preparing Data for LSTM Autoencoder\")\n",
    "    print(\"=\" * 40)\n",
    "\n",
    "    print(\"📊 Converting normal windows to arrays...\", end=\" \")\n",
    "    start_conversion = time.time()\n",
    "\n",
    "    # Convert normal windows to numpy arrays for training\n",
    "    normal_arrays = []\n",
    "    for i, window in enumerate(sampled_normal_windows):\n",
    "        if i % 200 == 0 and i > 0:\n",
    "            print(\n",
    "                f\"\\r📊 Converting normal windows to arrays... {i}/{len(sampled_normal_windows)}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        # Ensure consistent shape and convert to numpy\n",
    "        window_array = window.values if hasattr(window, \"values\") else window\n",
    "        normal_arrays.append(window_array)\n",
    "\n",
    "    print(\n",
    "        f\"\\r📊 Converting normal windows to arrays... ✅ ({len(normal_arrays)} processed)\"\n",
    "    )\n",
    "\n",
    "    print(\"📊 Converting anomaly windows to arrays...\", end=\" \")\n",
    "    # Convert anomaly windows to numpy arrays for testing\n",
    "    anomaly_arrays = []\n",
    "    for i, window in enumerate(sampled_anomaly_windows):\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(\n",
    "                f\"\\r📊 Converting anomaly windows to arrays... {i}/{len(sampled_anomaly_windows)}\",\n",
    "                end=\"\",\n",
    "            )\n",
    "        # Ensure consistent shape and convert to numpy\n",
    "        window_array = window.values if hasattr(window, \"values\") else window\n",
    "        anomaly_arrays.append(window_array)\n",
    "\n",
    "    print(\n",
    "        f\"\\r📊 Converting anomaly windows to arrays... ✅ ({len(anomaly_arrays)} processed)\"\n",
    "    )\n",
    "\n",
    "    normal_data = np.array(normal_arrays)\n",
    "    anomaly_data = np.array(anomaly_arrays)\n",
    "\n",
    "    conversion_time = time.time() - start_conversion\n",
    "    print(f\"⚡ Data conversion completed in {conversion_time:.2f} seconds\")\n",
    "\n",
    "    print(f\"\\n📐 Data shapes:\")\n",
    "    print(f\"   • Normal data: {normal_data.shape}\")\n",
    "    print(f\"   • Anomaly data: {anomaly_data.shape}\")\n",
    "\n",
    "    # Get dimensions\n",
    "    n_normal_samples, time_steps, n_features = normal_data.shape\n",
    "\n",
    "    print(f\"\\n📋 LSTM Autoencoder Configuration:\")\n",
    "    print(f\"   • Time steps per window: {time_steps}\")\n",
    "    print(f\"   • Features per time step: {n_features}\")\n",
    "    print(f\"   • Normal training samples: {n_normal_samples}\")\n",
    "    print(f\"   • Anomaly test samples: {anomaly_data.shape[0]}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # DATA PREPARATION (ALREADY SCALED)\n",
    "    # ============================================================\n",
    "    print(\"\\n📊 Data Already Preprocessed\")\n",
    "    print(\"=\" * 30)\n",
    "\n",
    "    print(\"✅ Using pre-scaled windowed data from data treatment process\")\n",
    "    # Data is already normalized from the windowing process - no additional scaling needed\n",
    "    normal_scaled = normal_data\n",
    "    anomaly_scaled = anomaly_data\n",
    "\n",
    "    print(f\"📏 Data characteristics:\")\n",
    "    print(\n",
    "        f\"   • Normal data range: [{np.min(normal_scaled):.3f}, {np.max(normal_scaled):.3f}]\"\n",
    "    )\n",
    "    print(\n",
    "        f\"   • Anomaly data range: [{np.min(anomaly_scaled):.3f}, {np.max(anomaly_scaled):.3f}]\"\n",
    "    )\n",
    "    print(f\"   • Data already optimized for neural network training\")\n",
    "\n",
    "    # ============================================================\n",
    "    # OPTIMIZED LSTM AUTOENCODER ARCHITECTURE\n",
    "    # ============================================================\n",
    "    print(\"\\n🧠 Building Optimized LSTM Autoencoder Architecture\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Optimized hyperparameters for faster training\n",
    "    latent_dim = 32  # Reduced from 64 for faster training\n",
    "    lstm_units = 64  # Reduced from 128 for faster training\n",
    "\n",
    "    print(f\"🏗️ Optimized Architecture Configuration:\")\n",
    "    print(f\"   • Input shape: ({time_steps}, {n_features})\")\n",
    "    print(f\"   • Encoder LSTM units: {lstm_units} (reduced for speed)\")\n",
    "    print(f\"   • Latent dimension: {latent_dim} (reduced for speed)\")\n",
    "    print(f\"   • Decoder LSTM units: {lstm_units}\")\n",
    "    print(f\"   • Output shape: ({time_steps}, {n_features})\")\n",
    "    print(f\"   • Dropout added for regularization\")\n",
    "\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(time_steps, n_features), name=\"input\")\n",
    "\n",
    "    # Encoder with dropout for regularization\n",
    "    encoded = LSTM(lstm_units, activation=\"relu\", name=\"encoder_lstm\")(input_layer)\n",
    "    encoded = Dropout(0.2, name=\"encoder_dropout\")(encoded)\n",
    "\n",
    "    # Latent representation (bottleneck)\n",
    "    latent = Dense(latent_dim, activation=\"relu\", name=\"latent\")(encoded)\n",
    "\n",
    "    # Decoder\n",
    "    decoded = RepeatVector(time_steps, name=\"repeat_vector\")(latent)\n",
    "    decoded = LSTM(\n",
    "        lstm_units, activation=\"relu\", return_sequences=True, name=\"decoder_lstm\"\n",
    "    )(decoded)\n",
    "    decoded = Dropout(0.2, name=\"decoder_dropout\")(decoded)\n",
    "    decoded = TimeDistributed(Dense(n_features), name=\"output\")(decoded)\n",
    "\n",
    "    # Create autoencoder model\n",
    "    autoencoder = Model(input_layer, decoded, name=\"optimized_lstm_autoencoder\")\n",
    "\n",
    "    # Compile model with optimized settings\n",
    "    autoencoder.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=0.002\n",
    "        ),  # Slightly higher learning rate for faster convergence\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"],\n",
    "    )\n",
    "\n",
    "    print(\"✅ Optimized LSTM Autoencoder model created\")\n",
    "\n",
    "    # Display model summary (compact)\n",
    "    print(f\"\\n📋 Model Summary:\")\n",
    "    print(f\"   • Total parameters: {autoencoder.count_params():,}\")\n",
    "    print(\n",
    "        f\"   • Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in autoencoder.trainable_weights]):,}\"\n",
    "    )\n",
    "    print(f\"   • Model architecture optimized for faster training\")\n",
    "\n",
    "    # ============================================================\n",
    "    # OPTIMIZED MODEL TRAINING WITH PROGRESS FEEDBACK\n",
    "    # ============================================================\n",
    "    print(\"\\n🚂 Training Optimized LSTM Autoencoder on Normal Data\")\n",
    "    print(\"=\" * 55)\n",
    "\n",
    "    # Split normal data into train/validation (80/20 split)\n",
    "    split_idx = int(0.8 * len(normal_scaled))\n",
    "    train_normal = normal_scaled[:split_idx]\n",
    "    val_normal = normal_scaled[split_idx:]\n",
    "\n",
    "    print(f\"📊 Training split:\")\n",
    "    print(f\"   • Training samples: {len(train_normal)}\")\n",
    "    print(f\"   • Validation samples: {len(val_normal)}\")\n",
    "\n",
    "    # Optimized callbacks for faster training\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,  # Reduced patience for faster training\n",
    "        restore_best_weights=True,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=3, min_lr=0.0001, verbose=1\n",
    "    )\n",
    "\n",
    "    print(f\"🚂 Starting optimized training...\")\n",
    "    print(f\"   • Max epochs: 50 (reduced for speed)\")\n",
    "    print(f\"   • Batch size: 64 (increased for efficiency)\")\n",
    "    print(f\"   • Early stopping patience: 5 epochs\")\n",
    "    print(f\"   • Learning rate reduction on plateau\")\n",
    "\n",
    "    training_start = time.time()\n",
    "\n",
    "    # Train autoencoder with optimized parameters\n",
    "    history = autoencoder.fit(\n",
    "        train_normal,\n",
    "        train_normal,  # Autoencoder: input = target\n",
    "        validation_data=(val_normal, val_normal),\n",
    "        epochs=50,  # Reduced from 100 for faster training\n",
    "        batch_size=64,  # Increased from 32 for faster training\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1,  # Show progress during training\n",
    "    )\n",
    "\n",
    "    training_time = time.time() - training_start\n",
    "    print(f\"\\n✅ Training completed in {training_time:.2f} seconds\")\n",
    "    print(f\"   • Epochs trained: {len(history.history['loss'])}\")\n",
    "    print(f\"   • Final training loss: {history.history['loss'][-1]:.6f}\")\n",
    "    print(f\"   • Final validation loss: {history.history['val_loss'][-1]:.6f}\")\n",
    "\n",
    "    # Quick training visualization\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\", linewidth=2)\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\", linewidth=2)\n",
    "    plt.title(\"Model Loss During Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"mae\"], label=\"Training MAE\", linewidth=2)\n",
    "    plt.plot(history.history[\"val_mae\"], label=\"Validation MAE\", linewidth=2)\n",
    "    plt.title(\"Model MAE During Training\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Absolute Error\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\n📊 Training Summary:\")\n",
    "    print(f\"   ✅ Model successfully trained on normal operation data\")\n",
    "    print(f\"   ✅ Training time: {training_time:.2f} seconds\")\n",
    "    print(f\"   ✅ Architecture optimized for speed and performance\")\n",
    "    print(f\"   ✅ Ready for anomaly detection evaluation\")\n",
    "\n",
    "    print(f\"\\n⚡ Performance Optimizations Applied:\")\n",
    "    print(f\"   • Reduced model complexity (64 LSTM units vs 128)\")\n",
    "    print(f\"   • Smaller latent dimension (32 vs 64)\")\n",
    "    print(f\"   • Smart data sampling for training efficiency\")\n",
    "    print(f\"   • Increased batch size for faster training\")\n",
    "    print(f\"   • Reduced epochs with early stopping\")\n",
    "    print(f\"   • Learning rate scheduling for optimal convergence\")\n",
    "\n",
    "else:\n",
    "    print(\n",
    "        \"❌ No data available. Please run the previous cell first to load normal and anomaly data.\"\n",
    "    )\n",
    "    autoencoder = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe37606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# QUICK AUTOENCODER TEST (OPTIONAL - FOR IMMEDIATE FEEDBACK)\n",
    "# ============================================================\n",
    "\n",
    "print(\"🔬 Quick Autoencoder Test for Immediate Feedback\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# This cell provides immediate feedback to ensure everything works\n",
    "# Run this first if you want to test the setup before full training\n",
    "\n",
    "if (\n",
    "    \"normal_windows\" in locals()\n",
    "    and normal_windows is not None\n",
    "    and len(normal_windows) > 0\n",
    "):\n",
    "\n",
    "    # Quick test with minimal data\n",
    "    print(\"🚀 Testing with minimal dataset for immediate feedback...\")\n",
    "\n",
    "    # Use only a tiny subset for testing\n",
    "    test_normal = normal_windows[:10]  # Just 10 samples for testing\n",
    "    test_anomaly = anomaly_windows[:5] if len(anomaly_windows) >= 5 else anomaly_windows\n",
    "\n",
    "    print(f\"🧪 Test data:\")\n",
    "    print(f\"   • Normal samples: {len(test_normal)}\")\n",
    "    print(f\"   • Anomaly samples: {len(test_anomaly)}\")\n",
    "\n",
    "    # Quick conversion test with class column removal\n",
    "    print(\"📊 Testing data conversion (removing class column)...\", end=\" \")\n",
    "    try:\n",
    "        test_normal_arrays = []\n",
    "        for window in test_normal:\n",
    "            # Get the DataFrame values and remove the class column\n",
    "            if hasattr(window, \"values\"):\n",
    "                window_data = window.copy()\n",
    "                # Remove 'class' column if it exists\n",
    "                if \"class\" in window_data.columns:\n",
    "                    window_data = window_data.drop(\"class\", axis=1)\n",
    "                    print(f\"\\n   📋 Removed 'class' column from DataFrame\")\n",
    "                window_array = window_data.values\n",
    "            else:\n",
    "                # If it's already an array, assume last column is class and remove it\n",
    "                if len(window.shape) == 2 and window.shape[1] > 1:\n",
    "                    window_array = window[:, :-1]  # Remove last column (class)\n",
    "                    print(f\"\\n   📋 Removed last column (assumed class) from array\")\n",
    "                else:\n",
    "                    window_array = window\n",
    "\n",
    "            test_normal_arrays.append(window_array)\n",
    "\n",
    "        test_normal_data = np.array(test_normal_arrays)\n",
    "        print(\"✅\")\n",
    "        print(f\"   • Test normal data shape: {test_normal_data.shape}\")\n",
    "\n",
    "        # Extract dimensions\n",
    "        test_samples, test_time_steps, test_features = test_normal_data.shape\n",
    "        print(f\"   • Time steps: {test_time_steps}\")\n",
    "        print(f\"   • Features: {test_features} (after removing class column)\")\n",
    "\n",
    "        # Check data characteristics\n",
    "        print(\n",
    "            f\"   • Data range: [{np.min(test_normal_data):.3f}, {np.max(test_normal_data):.3f}]\"\n",
    "        )\n",
    "        print(f\"   • Data type: {test_normal_data.dtype}\")\n",
    "\n",
    "        # Verify the first window columns if it's a DataFrame\n",
    "        if hasattr(test_normal[0], \"columns\"):\n",
    "            print(f\"   • Original columns: {list(test_normal[0].columns)}\")\n",
    "            if \"class\" in test_normal[0].columns:\n",
    "                print(\n",
    "                    f\"   • Features after removing class: {list(test_normal[0].drop('class', axis=1).columns)}\"\n",
    "                )\n",
    "\n",
    "        print(f\"\\n✅ Quick test successful! Data is ready for LSTM autoencoder.\")\n",
    "        print(f\"✅ Class column properly handled and removed from features.\")\n",
    "        print(f\"💡 You can now run the full training cell with confidence.\")\n",
    "        print(f\"⚡ Estimated full training time: ~2-5 minutes with optimized settings\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error in quick test: {str(e)}\")\n",
    "        print(f\"💡 Please check the data loading cell and try again\")\n",
    "\n",
    "        # Show more detailed error information\n",
    "        import traceback\n",
    "\n",
    "        print(f\"\\n🔍 Detailed error:\")\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "else:\n",
    "    print(\"❌ No normal_windows data available.\")\n",
    "    print(\"💡 Please run the data loading cell first.\")\n",
    "\n",
    "print(f\"\\n📋 Next Steps:\")\n",
    "print(f\"   1. ✅ Quick test completed - data is compatible\")\n",
    "print(f\"   2. ✅ Class column handling verified\")\n",
    "print(f\"   3. 🚂 Run the full training cell below for complete autoencoder\")\n",
    "print(f\"   4. 🔍 Proceed to anomaly detection evaluation\")\n",
    "print(f\"   5. 📊 Visualize results and performance metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b91df2",
   "metadata": {},
   "source": [
    "##  Introduction to Autoencoders for Novelty Detection (5 minutes)\n",
    "\n",
    "### What are Autoencoders?\n",
    "\n",
    "**Autoencoders** are neural networks designed to learn efficient data representations by training the network to copy its input to its output. They learn to compress and then reconstruct data.\n",
    "\n",
    "### Autoencoder Architecture:\n",
    "- **Input Layer**: Original data (e.g., sensor readings)\n",
    "- **Encoder**: Compresses input into lower-dimensional representation\n",
    "- **Latent Space**: Compressed representation (bottleneck)\n",
    "- **Decoder**: Reconstructs original data from compressed representation\n",
    "- **Output Layer**: Reconstructed data (should match input)\n",
    "\n",
    "### How Autoencoders Detect Novelty:\n",
    "\n",
    "1. **Training Phase**: Learn to reconstruct only normal data\n",
    "2. **Normal Data**: Low reconstruction error (model learned these patterns)\n",
    "3. **Anomalous Data**: High reconstruction error (model never saw these patterns)\n",
    "4. **Threshold**: Statistical boundary between normal and anomalous reconstruction errors\n",
    "\n",
    "### Why Autoencoders for Oil Well Data:\n",
    "\n",
    "#### Advantages:\n",
    "- **Unsupervised Learning**: Only need normal operation data\n",
    "- **Feature Learning**: Automatically discover important sensor patterns\n",
    "- **Dimensionality Reduction**: Handle high-dimensional sensor data efficiently\n",
    "- **Non-linear Patterns**: Capture complex relationships between sensors\n",
    "- **Reconstruction-Based**: Intuitive interpretation of anomaly scores\n",
    "\n",
    "#### LSTM Autoencoders Specifically:\n",
    "- **Temporal Modeling**: Handle time series sensor data naturally\n",
    "- **Sequential Dependencies**: Capture patterns across time steps\n",
    "- **Variable Sequences**: Adapt to different operational phases\n",
    "- **Memory Cells**: Remember long-term normal operation patterns\n",
    "\n",
    "### Novelty Detection Process:\n",
    "\n",
    "1. **Data Preparation**: Normalize and structure time series data\n",
    "2. **Model Training**: Train autoencoder on normal data only\n",
    "3. **Error Computation**: Calculate reconstruction errors for all data\n",
    "4. **Threshold Setting**: Use statistical methods (μ + 3σ) on normal errors\n",
    "5. **Anomaly Detection**: Flag samples with errors above threshold\n",
    "6. **Validation**: Test on known fault data to evaluate performance\n",
    "\n",
    "### Industrial Applications:\n",
    "- **Predictive Maintenance**: Detect equipment degradation early\n",
    "- **Quality Control**: Identify production anomalies\n",
    "- **System Monitoring**: Continuous health assessment\n",
    "- **Safety Systems**: Early warning for critical failures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "owl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}